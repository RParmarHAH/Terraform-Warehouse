{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94788d1-8768-4fe2-9a7c-8c4a078ecf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is my code \n",
    "import os\n",
    "import re\n",
    "import time  # Import the time module\n",
    "\n",
    "# Get the current time in microseconds before starting execution\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "# Get the current time in microseconds after finishing execution\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "# Calculate the elapsed time in microseconds\n",
    "elapsed_time_microseconds = (end_time - start_time) * 1e6  # Convert to microseconds\n",
    "\n",
    "# Print the elapsed time in microseconds\n",
    "print(f\"Elapsed time: {elapsed_time_microseconds:.2f} microseconds\")\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Specify the relative folder path containing .sql files\n",
    "relative_folder_path = 'SQL_Files/Table'\n",
    "\n",
    "# Combine the current working directory with the relative folder path\n",
    "folder_path = os.path.join(current_directory, relative_folder_path)\n",
    "\n",
    "sql_contents_list = []\n",
    "\n",
    "try:\n",
    "    # Get a list of all files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    # Filter out only the .sql files\n",
    "    sql_files = [file for file in files if file.endswith('.sql')]\n",
    "\n",
    "    # Read the contents of each .sql file and store them in a list\n",
    "    for sql_file in sql_files:\n",
    "        file_path = os.path.join(folder_path, sql_file)\n",
    "        with open(file_path, 'r') as file:\n",
    "            sql_contents = file.read()\n",
    "            sql_contents_list.append(sql_contents)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Folder not found: {folder_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "# This code removes double quotes outside of DDL, including Database, schema, table name\n",
    "def remove_outer_quotes(sql):\n",
    "    ls1 = sql.split(\"(\")[0].replace('\"', '')\n",
    "    ls2 = [\"(\" + i for i in sql.split(\"(\")[1:]]\n",
    "    ls2.insert(0, ls1)\n",
    "    sql = \"\".join(ls2)\n",
    "\n",
    "    return sql\n",
    "\n",
    "# resource_database_name = []\n",
    "# resource_schema_name = []\n",
    "# resource_table = []\n",
    "# print(resource_database_name)\n",
    "\n",
    "# for i in resource_database_name:\n",
    "#     print(i)\n",
    "    \n",
    "def check_table_comment(sql):\n",
    "    comment_match = re.search(r\"comment\\s*=\\s*'([^']*)'\", sql, re.IGNORECASE)\n",
    "    \n",
    "    # Assuming 'command' contains your SQL command as a string\n",
    "    command = sql.strip().upper()\n",
    "    create_commands = re.findall(r\"CREATE(?:\\s+OR\\s+REPLACE)?\\s+TABLE(.*?)\\(\", command, re.DOTALL)\n",
    "    # Iterate over each match in the list\n",
    "\n",
    "    for create_command in create_commands:\n",
    "        # Perform the split operation on each matched string\n",
    "        database_info = create_command.strip().split('.')\n",
    "\n",
    "        # Extract database name, schema name, and table name\n",
    "        database_name = database_info[0].replace('\"', '')\n",
    "        schema_name = database_info[1].replace('\"', '')\n",
    "        table_name = database_info[2].replace('\"', '')\n",
    "        \n",
    "        from datetime import datetime\n",
    "\n",
    "        current_date = datetime.now().date()\n",
    "\n",
    "        current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        dynamic_db = ''\n",
    "        dynamic__main_db = ''\n",
    "        if database_name.endswith(\"_DEV\"):\n",
    "            dynamic_db += database_name.replace(\"_DEV\", \"_${var.SF_ENVIRONMENT}\")\n",
    "            dynamic__main_db += database_name.replace(\"_DEV\", \"\")\n",
    "        elif database_name.endswith(\"_PROD\"):\n",
    "            dynamic_db += database_name.replace(\"_PROD\", \"_${var.SF_ENVIRONMENT}\")\n",
    "            dynamic__main_db += database_name.replace(\"_PROD\", \"\")\n",
    "\n",
    "            \n",
    "        purpose_value = ''\n",
    "        if 'DISC'==dynamic__main_db:\n",
    "            purpose = 'Discovery Data Population'\n",
    "            purpose_value+=purpose\n",
    "        elif 'DW'==dynamic__main_db and ('HAH'==schema_name or 'STAGE'==schema_name):\n",
    "            purpose = 'Business Data Population'\n",
    "            purpose_value+=purpose\n",
    "        elif 'DW'==dynamic__main_db and 'INTEGRATION'==schema_name :\n",
    "            purpose = 'Business Integration Data Population'\n",
    "            purpose_value+=purpose\n",
    "        elif 'DW'==dynamic__main_db and 'REPORT'==schema_name :\n",
    "            purpose = 'Business Report Data Population'\n",
    "            purpose_value+=purpose\n",
    "        elif 'APP_DB'==dynamic__main_db:\n",
    "            purpose = 'APP_DB Data Population'\n",
    "            purpose_value+=purpose\n",
    "        elif 'APP_DB'==dynamic__main_db:\n",
    "            purpose = 'APP_DB Data Population'\n",
    "            purpose_value+=purpose\n",
    "        elif 'ETL_Management'==dynamic__main_db and 'AUDIT'==schema_name :\n",
    "            purpose = 'ETL Audit Data Population'\n",
    "            purpose_value+=purpose\n",
    "        elif 'ETL_Management'==dynamic__main_db and 'CONFIG'==schema_name :\n",
    "            purpose = 'ETL CONFIG Data Population'\n",
    "            purpose_value+=purpose\n",
    "        elif 'DEDUPE'==dynamic__main_db :\n",
    "            purpose = 'Dedupe Data Population'\n",
    "            purpose_value+=purpose\n",
    "            \n",
    "        if comment_match:\n",
    "            comment = comment_match.group(1)\n",
    "            return comment\n",
    "        else:\n",
    "            comment  = f''' \n",
    "    --*****************************************************************************************************************************\n",
    "\n",
    "    -- NAME :  {database_name}.{schema_name}.{table_name}\n",
    "\n",
    "    -- Purpose : {purpose_value}\n",
    "\n",
    "    -- Project : {schema_name}\n",
    "\n",
    "    -- Source Data update Frequency : 60 min\n",
    "\n",
    "    --\n",
    "\n",
    "    -- DEVELOPMENT LOG:\n",
    "\n",
    "    -- DATE        AUTHOR                NOTES:\n",
    "\n",
    "    -- ----------  -------------------   -----------------------------------------------------------------------------------------------\n",
    "\n",
    "    -- {current_date}  Terraform            Initial Development(from Terraform GitHub Action Deployment)\n",
    "\n",
    "    --*****************************************************************************************************************************\n",
    "            '''\n",
    "            return comment\n",
    "\n",
    "\n",
    "resource_table_name_list = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Main Python code\n",
    "def python_terraform(sql, comment):\n",
    "    comment = check_table_comment(sql)\n",
    "    \n",
    "\n",
    "       \n",
    "    code = \"\"\n",
    "    ddl = sql.split(';')\n",
    "\n",
    "    for command in ddl:\n",
    "        command = command.strip().upper()\n",
    "        create_commands = re.findall(r\"CREATE(?:\\s+OR\\s+REPLACE)?\\s+TABLE(.*?)\\(\", command, re.DOTALL)\n",
    "\n",
    "        # Get the database name, schema name, table name\n",
    "        for create_command in create_commands:\n",
    "            create_command = create_command.strip()\n",
    "            database_info = create_command.split()[0].split('.')\n",
    "            database_name = database_info[0].replace('\"', '')\n",
    "            schema_name = database_info[1].replace('\"', '')\n",
    "            table_name = database_info[2].replace('\"', '')\n",
    "\n",
    "#                 global resource_table_name\n",
    "            # resource_database_name.append(database_name)\n",
    "            # resource_schema_name.append(schema_name)\n",
    "            # resource_table.append(table_name)\n",
    "\n",
    "\n",
    "            # data_retention_time_in_days_schema = 1\n",
    "\n",
    "            # Set the dynamic database name / remove dev, prod name\n",
    "            dynamic_db = ''\n",
    "            dynamic__main_db = ''\n",
    "            if database_name.endswith(\"_DEV\"):\n",
    "                dynamic_db += database_name.replace(\"_DEV\", \"_${var.SF_ENVIRONMENT}\")\n",
    "                dynamic__main_db += database_name.replace(\"_DEV\", \"\")\n",
    "            elif database_name.endswith(\"_PROD\"):\n",
    "                dynamic_db += database_name.replace(\"_PROD\", \"_${var.SF_ENVIRONMENT}\")\n",
    "                dynamic__main_db += database_name.replace(\"_PROD\", \"\")\n",
    "\n",
    "\n",
    "\n",
    "            # Create table\n",
    "            resource_table_name = f\"resource \\\"snowflake_table\\\" \\\"{dynamic__main_db}_{schema_name}_{table_name}\\\"\"\n",
    "            code += f\"{resource_table_name} {{\\n\"\n",
    "            code += f\"\\tdatabase = \\\"{dynamic_db}\\\"\\n\"\n",
    "\n",
    "            resource_table_name_demo = f'{dynamic__main_db}_{schema_name}_{table_name}'\n",
    "            resource_table_name_list.append(resource_table_name_demo)\n",
    "\n",
    "            code += f\"\\tschema = \\\"{schema_name}\\\"\\n\"\n",
    "            code += f\"\\tname = \\\"{table_name}\\\"\\n\"\n",
    "            # code += f\"\\tdata_retention_days = {data_retention_time_in_days_schema}\\n\"\n",
    "            code += f\"\\tchange_tracking = false\\n\"\n",
    "            code += f\"\\tcomment = \\\"{comment}\\\"\\n\"\n",
    "\n",
    "            # Find the column names\n",
    "            column_matches = re.findall(\n",
    "                r'\"([^\"]+)\"|([a-zA-Z_][\\w\\s/\\-*^]*)\\s+(?:AS\\s+)?(?:(?:VARCHAR|CHAR|NUMBER|BINARY|STRING|TIMESTAMP_NTZ|TIMESTAMP_TZ|TIMESTAMP|TIME|ARRAY|VARIANT|OBJECT|TIMESTAMP_LTZ|GEOGRAPHY|GEOMETRY|BLOB|CLOB|TINYINT|DECIMAL)\\([\\d,]+\\)|ARRAY|VARCHAR|TIMESTAMP_NTZ|TIMESTAMP_TZ|TIMESTAMP|BOOLEAN|TEXT|DATE|INT|INTEGER|FLOAT|VARIANT|OBJECT|TIMESTAMP_LTZ|GEOGRAPHY|GEOMETRY|BLOB|CLOB|TINYINT|DECIMAL)',\n",
    "                sql.replace('\\n', ' '))\n",
    "            column_names = [column[0] or column[1] for column in column_matches if column[0] or column[1]]\n",
    "            column_names = [column.strip() for column in column_names if column.strip() != 'AS']\n",
    "\n",
    "            # Find the Not Null column names\n",
    "            not_null_pattern = r'(?:\"(.*?)\".*?NOT NULL|(\\w+)\\s+.*?NOT NULL)'\n",
    "            matches = re.findall(not_null_pattern, sql)\n",
    "            not_null_columns = [match[0] or match[1] for match in matches]\n",
    "\n",
    "            # Find the Comment column names\n",
    "            Comment_pattern = r'(?:\"(.*?)\".*?COMMENT\\s+\\'(.*?)\\'|(\\w+)\\s+.*?COMMENT\\s+\\'(.*?)\\')'\n",
    "            matches = re.findall(Comment_pattern, sql)\n",
    "            comment_columns = [match[0] or match[2] for match in matches]\n",
    "            comment_values = [match[1] or match[3] for match in matches]\n",
    "\n",
    "            # Find generated_always_as in columns\n",
    "            generated_pattern = r'(?:\\\"(.*?)\\\"|\\b(\\w+)\\b).*?(?<=AS\\s)\\((.*?)\\)\\s*(?:(?=COMMENT)|(?=NOT\\s+NULL)|(?=,|$))'\n",
    "            generated_always_as = re.findall(generated_pattern, sql, re.MULTILINE)\n",
    "\n",
    "            # Find DEFAULT values in columns\n",
    "            DEFAULT_pattern = r'(?:\\\"(.*?)\\\"|\\b(\\w+)\\b).*?(?<=DEFAULT\\s)([^,\\n]*?)(?=\\s+(?:COMMENT|NOT\\s+NULL|,\\s*$))'\n",
    "            DEFAULT_matches = re.findall(DEFAULT_pattern, sql, re.MULTILINE | re.IGNORECASE)\n",
    "\n",
    "            # Find Check constraints in columns\n",
    "            pattern_check = r'(?:\\\"(.*?)\\\"|\\b(\\w+)\\b)\\s+.*?CHECK\\s+\\((.*?)\\)\\s*(?:(?:COMMENT|NOT\\s+NULL|,\\s*$))'\n",
    "            check_matches = re.findall(pattern_check, sql)\n",
    "\n",
    "            # Find the data types\n",
    "            data_type_matches = re.findall(\n",
    "                r'(\"([^\"]+)\"|([\\w\\s/*&^?!-]+))\\s+((?:VARCHAR|CHAR|NUMBER|BINARY|STRING|TIMESTAMP_NTZ|TIMESTAMP_TZ|TIMESTAMP|TIME|BOOLEAN|TEXT|DATE|INT|INTEGER|FLOAT|VARIANT|ARRAY|OBJECT|TIMESTAMP_LTZ|GEOGRAPHY|GEOMETRY|BLOB|CLOB|TINYINT|DECIMAL)(?:\\([\\d,]+\\))?)',\n",
    "                sql.replace('\\n', ' '))\n",
    "\n",
    "            column_name_list = []\n",
    "            data_types_list = []\n",
    "            for match in data_type_matches:\n",
    "                full_match, quoted_column_name, unquoted_column_name, data_type = match\n",
    "                column_name = quoted_column_name or unquoted_column_name\n",
    "                column_name = column_name.strip()\n",
    "                data_type = data_type.strip()\n",
    "                column_name_list.append(column_name)\n",
    "                data_types_list.append(data_type)\n",
    "\n",
    "            # Generate Terraform code for each column\n",
    "            for col, j in zip(column_names, data_types_list):\n",
    "                code += f\"\\ncolumn {{\\n\"\n",
    "                code += f\"\\tname = \\\"{col}\\\"\\n\"\n",
    "                code += f\"\\ttype = \\\"{j}\\\"\\n\"\n",
    "\n",
    "                # Handle generated_always_as column\n",
    "                for quoted_column, unquoted_column, expression in generated_always_as:\n",
    "                    generated_column_name = quoted_column.strip() if quoted_column else unquoted_column.strip()\n",
    "                    expression_cleaned = expression.strip()\n",
    "\n",
    "                    if col == generated_column_name:\n",
    "                        code += f\"\\tgenerated_always_as  = \\\"{expression_cleaned}\\\"\\n\"\n",
    "\n",
    "                # Handle Default column\n",
    "                for match_def in DEFAULT_matches:\n",
    "                    DEFAULT_column_name = match_def[0] if match_def[0] else match_def[1]\n",
    "                    DEFAULT_default_value = match_def[2]\n",
    "                    DEFAULT_column_name = DEFAULT_column_name.replace('\"', '').strip()\n",
    "                    DEFAULT_default_value = DEFAULT_default_value.replace('\"', '').replace(\"'\", '').strip()\n",
    "\n",
    "                    if col == DEFAULT_column_name:\n",
    "                        code += f\"\\tdefault = \\\"{DEFAULT_default_value}\\\"\\n\"\n",
    "\n",
    "                # Handle Check column\n",
    "                for check_match in check_matches:\n",
    "                    check_column_name = check_match[0] or check_match[1]\n",
    "                    check_condition = check_match[2]\n",
    "                    if col == check_column_name:\n",
    "                        code += f\"\\tcheck {{\\n\"\n",
    "                        code += f\"\\tcondition = \\\"{check_condition}\\\"\\n\"\n",
    "                        code += \"}\\t\\n\"\n",
    "\n",
    "                # Handle Not Null column\n",
    "                if col in not_null_columns:\n",
    "                    code += f\"\\tnullable = false\\n\"\n",
    "                else:\n",
    "                    code += f\"\\tnullable = true\\n\"\n",
    "\n",
    "                # Handle Comment column\n",
    "                for comm_col, comm_values in zip(comment_columns, comment_values):\n",
    "                    if comm_col == col:\n",
    "                        code += f\"\\tcomment = \\\"{comm_values}\\\"\\n\"\n",
    "\n",
    "                code += \"}\\n\\n\"\n",
    "\n",
    "            code += \"}\\n\\n\"\n",
    "    return code\n",
    "\n",
    "for sql_contents in sql_contents_list:\n",
    "    sql_without_quotes = remove_outer_quotes(sql_contents)\n",
    "    comment = check_table_comment(sql_without_quotes)  # Get the comment for the SQL content\n",
    "    main = python_terraform(sql_without_quotes, comment)  # Call python_terraform with both sql and comment\n",
    "    # Extract database name and schema name from the SQL content\n",
    "    extract_schema_database_table = re.search(r'\\b(\\w+)\\.(\\w+)\\.(\\w+)', sql_without_quotes)\n",
    "    if extract_schema_database_table:\n",
    "        database_name, schema_name, table_name = extract_schema_database_table.groups()\n",
    "\n",
    "        # Update the output folder path to include database name and schema name\n",
    "        output_folder = os.path.join(current_directory, 'Terraform_Files', database_name, schema_name, 'Table')\n",
    "\n",
    "        try:\n",
    "            os.makedirs(output_folder, exist_ok=True)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while creating the output folder: {e}\")\n",
    "\n",
    "#         Write Terraform code to the appropriate output file\n",
    "        try:\n",
    "            dynamic_db = ''\n",
    "            dynamic__main_db = ''\n",
    "            if database_name.endswith(\"_DEV\"):\n",
    "                dynamic_db += database_name.replace(\"_DEV\", \"_${var.SF_ENVIRONMENT}\")\n",
    "                dynamic__main_db += database_name.replace(\"_DEV\", \"\")\n",
    "            elif database_name.endswith(\"_PROD\"):\n",
    "                dynamic_db += database_name.replace(\"_PROD\", \"_${var.SF_ENVIRONMENT}\")\n",
    "                dynamic__main_db += database_name.replace(\"_PROD\", \"\")\n",
    "\n",
    "            resource_table_name = f\"{dynamic__main_db}_{schema_name}_{table_name}\"\n",
    "            output_filename = os.path.join(output_folder, f\"{resource_table_name}.tf\")\n",
    "\n",
    "            with open(output_filename, 'w') as tf_file:\n",
    "                tf_file.write(main)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while writing the output file: {e}\")\n",
    "    else:\n",
    "        print(\"Unable to extract database name and schema name from the SQL content.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
