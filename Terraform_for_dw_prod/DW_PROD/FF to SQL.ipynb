{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0d4d5fe-c372-49a3-bbc1-dfb54e6faa09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE_FORMAT PUBLIC.CSV_AD DDL saved to SQL_Files\\File_Format\\PUBLIC.CSV_AD.sql\n",
      "FILE_FORMAT PUBLIC.CSV_FORMAT DDL saved to SQL_Files\\File_Format\\PUBLIC.CSV_FORMAT.sql\n",
      "FILE_FORMAT PUBLIC.CSV_FORMAT_ISO_8859_15_AB DDL saved to SQL_Files\\File_Format\\PUBLIC.CSV_FORMAT_ISO_8859_15_AB.sql\n",
      "FILE_FORMAT PUBLIC.CSV_FORMAT_ONE_HEAD_ROW DDL saved to SQL_Files\\File_Format\\PUBLIC.CSV_FORMAT_ONE_HEAD_ROW.sql\n",
      "FILE_FORMAT PUBLIC.CSV_FORMAT_TEST DDL saved to SQL_Files\\File_Format\\PUBLIC.CSV_FORMAT_TEST.sql\n",
      "FILE_FORMAT PUBLIC.CSV_FORMAT_TEST_AD DDL saved to SQL_Files\\File_Format\\PUBLIC.CSV_FORMAT_TEST_AD.sql\n",
      "FILE_FORMAT PUBLIC.CSV_FORMAT_TEST_AD_2 DDL saved to SQL_Files\\File_Format\\PUBLIC.CSV_FORMAT_TEST_AD_2.sql\n",
      "FILE_FORMAT PUBLIC.CSV_FORMAT_TEST_JP DDL saved to SQL_Files\\File_Format\\PUBLIC.CSV_FORMAT_TEST_JP.sql\n",
      "FILE_FORMAT PUBLIC.CSV_FORMAT_TEST_WO_BACKSLASH DDL saved to SQL_Files\\File_Format\\PUBLIC.CSV_FORMAT_TEST_WO_BACKSLASH.sql\n",
      "FILE_FORMAT PUBLIC.CSV_FORMAT_TRUSTPOINT DDL saved to SQL_Files\\File_Format\\PUBLIC.CSV_FORMAT_TRUSTPOINT.sql\n",
      "FILE_FORMAT PUBLIC.CSV_SKIP_HEADER DDL saved to SQL_Files\\File_Format\\PUBLIC.CSV_SKIP_HEADER.sql\n",
      "FILE_FORMAT PUBLIC.CSV_ZIPCODES DDL saved to SQL_Files\\File_Format\\PUBLIC.CSV_ZIPCODES.sql\n",
      "FILE_FORMAT PUBLIC.MY_CSV_FORMAT DDL saved to SQL_Files\\File_Format\\PUBLIC.MY_CSV_FORMAT.sql\n",
      "FILE_FORMAT PUBLIC.MY_JSON_FORMAT DDL saved to SQL_Files\\File_Format\\PUBLIC.MY_JSON_FORMAT.sql\n",
      "FILE_FORMAT PUBLIC.PSV DDL saved to SQL_Files\\File_Format\\PUBLIC.PSV.sql\n",
      "FILE_FORMAT PUBLIC.CSV_SURVEY DDL saved to SQL_Files\\File_Format\\PUBLIC.CSV_SURVEY.sql\n",
      "FILE_FORMAT PUBLIC.PARSE_CSV_FORMAT DDL saved to SQL_Files\\File_Format\\PUBLIC.PARSE_CSV_FORMAT.sql\n",
      "FILE_FORMAT PUBLIC.PSV_WITH_HEADER DDL saved to SQL_Files\\File_Format\\PUBLIC.PSV_WITH_HEADER.sql\n",
      "FILE_FORMAT PUBLIC.PSV_ZIPCODES DDL saved to SQL_Files\\File_Format\\PUBLIC.PSV_ZIPCODES.sql\n",
      "FILE_FORMAT PUBLIC.TAB_FORMAT DDL saved to SQL_Files\\File_Format\\PUBLIC.TAB_FORMAT.sql\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "import snowflake.connector\n",
    "import os\n",
    "\n",
    "# Replace these with your Snowflake account credentials and connection details\n",
    "account = ''  # Replace with your Snowflake account URL\n",
    "warehouse = 'DEMO_WH'\n",
    "database = 'DW_PROD'\n",
    "schema = 'list_schema'\n",
    "username = ''  # Replace with your Snowflake username\n",
    "password = ''  # Replace with your Snowflake password\n",
    "\n",
    "# Create the SQL_Files and FileFormat folders\n",
    "sql_files_dir = \"SQL_Files\"\n",
    "file_format_dir = os.path.join(sql_files_dir, \"File_Format\")\n",
    "\n",
    "if not os.path.exists(sql_files_dir):\n",
    "    os.mkdir(sql_files_dir)\n",
    "\n",
    "if not os.path.exists(file_format_dir):\n",
    "    os.mkdir(file_format_dir)\n",
    "\n",
    "# Snowflake connection\n",
    "conn = snowflake.connector.connect(\n",
    "    user=username,\n",
    "    password=password,\n",
    "    account=account,\n",
    "    warehouse=warehouse,\n",
    "    database=database,\n",
    "    schema=schema,\n",
    "    role='SYSADMIN'\n",
    ")\n",
    "\n",
    "# Create a cursor to execute SQL queries\n",
    "cursor = conn.cursor()\n",
    "\n",
    "list_schema = ['ACROSS_DEDUPE','HAH','INTEGRATION','PUBLIC','REPORT','STAGE']\n",
    "FORMAT_NAME = []\n",
    "            \n",
    "# Execute the query to get the list of procedures\n",
    "for schema in list_schema:\n",
    "    # Query Snowflake to get a list of procedures in the specified database and schema\n",
    "    query = \"\"\"select file_format_schema, file_format_name from information_schema.file_formats\n",
    "             where file_format_schema = '{0}'\n",
    "            \"\"\".format(schema)\n",
    "\n",
    "    cursor.execute(query)\n",
    "    # Fetch the results\n",
    "    format_names = cursor.fetchall()\n",
    "    FORMAT_NAME.extend(format_names)\n",
    "\n",
    "\n",
    "# Close the cursor and connection when done with the procedure query\n",
    "cursor.close()\n",
    "\n",
    "file_formats_to_extract = []\n",
    "for i in FORMAT_NAME:\n",
    "    schema_name = i[0]\n",
    "    file_format_name = i[1]\n",
    "    full_name = f\"{schema_name}.{file_format_name}\"\n",
    "    file_formats_to_extract.append(full_name)\n",
    "\n",
    "# Function to extract and save DDL statements to files\n",
    "def extract_and_save_ddl(object_type, object_name):\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Create a query to extract DDL statements using GET_DDL\n",
    "    query = f\"SELECT GET_DDL('{object_type}', '{object_name}',true);\"\n",
    "\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        result = cursor.fetchone()\n",
    "\n",
    "        if result:\n",
    "            ddl_statement = result[0]\n",
    "\n",
    "            # Update the output directory to use \"fileformat\"\n",
    "            output_directory = os.path.join('SQL_Files', 'File_Format')\n",
    "\n",
    "            # Ensure the output directory exists, or create it\n",
    "            os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "            # Update the output filename to use the new directory path\n",
    "            output_filename = os.path.join(output_directory, f'{object_name}.sql')\n",
    "\n",
    "            # Replace comments and print statements for consistency\n",
    "            print(f'{object_type} {object_name} DDL saved to {output_filename}')\n",
    "\n",
    "              # Save the DDL statement to the output file\n",
    "            with open(output_filename, 'w') as file:\n",
    "                file.write(ddl_statement)\n",
    "        else:\n",
    "            print(f'{object_type} {object_name} not found.')\n",
    "            \n",
    "\n",
    "    except snowflake.connector.errors.ProgrammingError as e:\n",
    "        print(f\"Error extracting {object_type} {object_name}: {str(e)}\")\n",
    "    finally:\n",
    "        cursor.close()\n",
    "\n",
    "# Iterate over the file formats and extract DDL\n",
    "for file_format_name in file_formats_to_extract:\n",
    "    extract_and_save_ddl('FILE_FORMAT', file_format_name)\n",
    "\n",
    "# Close the Snowflake connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6158bfce-40c9-4caf-a9de-7fc9d88b4e07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
